# Aplicación de Random forest
Explicación de Random forest

# Carga de datos
```{r}
set.seed(123)
install.packages("randomForest")
library(randomForest)
install.packages("caTools")
library(caTools)
install.packages("caret")
library("caret")
# library("klaR")
```


Cargamos los datos de entrenamiento y de pruebas preprocesados (Ver notebook data_analysis.Rmd)


```{r}
train <- read.csv("dataset/train_preprocessed.data", sep=",", row.names=NULL, header=TRUE)
head(train)
dim(train)

test <- read.csv("dataset/test_preprocessed.data", sep=",", row.names=NULL, header=TRUE)
head(test)
dim(test)
```

Transformamos los datos (TODO: Explicar)

```{r}
summary(train)
dim(train)	
```

Aplicamos las transformaciones 
```{r}
transform_data <- function(dataframe) {
    dataframe <- transform(dataframe, age=as.integer(age), workclass=as.factor(workclass),
        fnlwgt=as.numeric(fnlwgt), education=as.factor(education), education_num=as.integer(education_num),
        marital_status=as.factor(marital_status), occupation=as.factor(occupation), relationship=as.factor(relationship),
        race=as.factor(race), sex=as.factor(sex), capital_gain=as.numeric(capital_gain), capital_loss=as.numeric(capital_loss),
        hours_per_week=as.integer(hours_per_week), native_country=as.factor(native_country), target=as.factor(target),
        hours_per_week_categorical=as.factor(hours_per_week_categorical),has_capital_gain=as.factor(has_capital_gain),
        has_capital_loss=as.factor(has_capital_loss)
    )

    return(dataframe)
}
```



```{r}
train <- transform_data(train)
summary(train)	
dim(train)

test <- transform_data(test)
summary(test)
dim(test)
```

Seleccionamos los atributos específicos que serán usados para entrenar el modelo
```{r}

selected_attributes <- c("age", "fnlwgt", "workclass", "education", "marital_status", "occupation", "relationship", 
"race", "sex", "native_country", "hours_per_week_categorical", "has_capital_gain", "has_capital_loss", "target")

train <- train[selected_attributes]

test <- test[selected_attributes]

levels(test$native_country) <- levels(train$native_country)

```


Definimos una función que ejecute el modelo con una configuración determinada
```{r}
train_and_evaluate_random_forest_with_configuration <- function(conf_number, train_set, test_set, 
                                        ntree_value, mtry_value, importance_value) {
    # Print configuration used
    # Configuración #X, ntree=Y, mtry=Z, importance=W
    print("####################################")
    print(paste("Configuración #", conf_number, ", ntree=", ntree_value, ", mtry=", mtry_value, ", importance=", importance_value))

    # Train model
    model_rf <- randomForest(target ~ ., data=train_set,
        ntree=ntree_value, mtry=mtry_value, importance=importance_value)

    # Predict on the training set
    y_pred_train <- predict(model_rf, new_data = train_set)
    train_precision <- precision(data=y_pred_train, reference=train_set$target, relevant=">50K")
    train_recall <- recall(data=y_pred_train, reference=train_set$target, relevant=">50K")
    train_f1 <- F_meas(data=y_pred_train, reference=train_set$target, relevant=">50K")

    levels(test_set$native_country) <- levels(train_set$native_country)

    # Predict on the test set
    y_pred_test <- predict(model_rf, test_set)
    print(length(y_pred_test))
    test_precision <- precision(data=y_pred_test, reference=test_set$target, relevant=">50K")
    test_recall <- recall(data=y_pred_test, reference=test_set$target, relevant=">50K")
    test_f1 <- F_meas(data=y_pred_test, reference=test_set$target, relevant=">50K")

    # Print metrics in both training and test sets (in a single line)
    print(paste("Train precision: ", train_precision, ", recall: ", train_recall, ", F1-Score: ", train_f1))
    print(paste("Test precision: ", test_precision, ", recall: ", test_recall, ", F1-Score: ", test_f1))

    # Return F1-Score and model
    return(list(test_f1, model_rf))

}
```

```{r}
# Hiperparámetros a configurar
ntree_values <- c(10, 100, 500, 1000)
mtry_values <- c(2.0,3.0,4.0,6.0)
importance_values <- c(FALSE, TRUE)

# Contador de configuraciones 
i <- 1

# Orden: ntree, mtry, importance
best_configuration <- list(10, 2.0, FALSE)
best_f1_score <- 0.0
best_model <- NULL

# TODO: Definir función de entrenamiento y crear for loops anidados

```


```{r}
model_rf <- train_and_evaluate_random_forest_with_configuration(1, train, test, 100, 3.0, TRUE)

```


```{r}
model_rf
```

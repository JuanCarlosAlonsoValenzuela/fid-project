# Naive Bayes
En este notebook se aplica el modelo probabilístico Naive Bayes, se ha utilizado la función [naiveBayes](https://rpubs.com/maulikpatel/224581), así como el paquete [Caret](https://topepo.github.io/caret/) para calcular las métricas

# Carga de datos
Comenzamos cargando las librerías necesarias.

```{r}
set.seed(123)
library(naivebayes)
library("klaR")
library("caret")
library(e1071)
```

Cargamos los datos de entrenamiento y de pruebas preprocesados (Ver notebook data_analysis.Rmd)
```{r}
train <- read.csv("dataset/train_preprocessed.data", sep=",", row.names=NULL, header=TRUE)
head(train)
dim(train)

test <- read.csv("dataset/test_preprocessed.data", sep=",", row.names=NULL, header=TRUE)
head(test)
dim(test)
```

```{r}
summary(train)
```

# Preparación y preprocesado de los datos 
La clase a predecir es target (Posibles valores: <=50K, >50K).

Age es un atributo numérico, por lo que lo convertimos a categórico utilizando la siguiente función:
```{r}
convert_age_to_categorical <- function(x) {
    age <- as.numeric(x['age'])
    decade <- floor(age/10)*10
    decade <- as.character(paste(decade, decade+10, sep="_"))
    return(decade)
}	
```	

Aplicamos la función definida en el chunk anterior a los conjuntos de entrenamiento y pruebas:

```{r}	
decade_train <- apply(train, 1, convert_age_to_categorical)
train <- cbind(train, decade=decade_train)

decade_test <- apply(test, 1, convert_age_to_categorical)
test <- cbind(test, decade=decade_test)
head(train)
head(test)
```

Definimos una función que transforme los valores de los atributos para que R pueda interpretarlos correctamente, por ejemplo, identificando las variables categóricas como tal, en lugar de como simples strings.

```{r}
transform_data <- function(dataframe) {
    dataframe <- transform(dataframe, age=as.integer(age), workclass=as.factor(workclass),
        fnlwgt=as.numeric(fnlwgt), education=as.factor(education), education_num=as.integer(education_num),
        marital_status=as.factor(marital_status), occupation=as.factor(occupation), relationship=as.factor(relationship),
        race=as.factor(race), sex=as.factor(sex), capital_gain=as.numeric(capital_gain), capital_loss=as.numeric(capital_loss),
        hours_per_week=as.integer(hours_per_week), native_country=as.factor(native_country), target=as.factor(target),
        hours_per_week_categorical=as.factor(hours_per_week_categorical),has_capital_gain=as.factor(has_capital_gain),
        has_capital_loss=as.factor(has_capital_loss), decade=as.factor(decade)
    )

    return(dataframe)
}
```

Aplicamos la transformación a los conjuntos de entrenamiento y pruebas:

```{r}
train <- transform_data(train)
summary(train)	
dim(train)

test <- transform_data(test)
summary(test)
dim(test)
```

Seleccionamos los atributos que se emplearán para entrenar y evaluar el modelo. Descartamos las versiones numéricas de todos los atributos.

```{r}
selected_attributes <- c("decade", "workclass", "education", "marital_status", "occupation", "relationship", 
"race", "sex", "native_country", "hours_per_week_categorical", "has_capital_gain", "has_capital_loss", "target")
train <- train[selected_attributes]

head(train)	
```	

```{r}
test <- test[selected_attributes]

head(test)
```	


```{r}
summary(train)	
summary(test)
```

# Entrenamiento del modelo y optimización de hiperparámetros
La función inferior define el modelo Naive Bayes y se aplica a los conjuntos de entrenamiento y pruebas dados unos valores de los hiperparámetros laplace y epsilon. También calcula el rendimiento del modelo en los conjuntos de entrenamiento y pruebas en términos de precision, recall y F1-Score.

```{r}
train_and_evaluate_naive_bayes_with_configuration <- function(conf_number, train_set, test_set, 
                                laplace_value, eps_value) {
    # Imprimir configuración usada
    # Configuración #X, laplace=Y, eps=Z
    print("####################################")
    print(paste("Configuración #", conf_number, ", laplace=", laplace_value, ", eps=", eps_value))

    # Entrenar modelo
    model_nb <- naiveBayes(target ~ ., data=train_set, laplace=laplace_value, eps=eps_value)

    # Predecir en el conjunto de entrenamiento
    y_pred_train <- predict(model_nb, newdata = train_set)

    train_precision <- precision(data=y_pred_train, reference=train_set$target, relevant=">50K")
    train_recall <- recall(data=y_pred_train, reference=train_set$target, relevant=">50K")
    train_f1 <- F_meas(data=y_pred_train, reference=train_set$target, relevant=">50K")

    # Predecir en el conjunto de pruebas
    y_pred_test <- predict(model_nb, newdata = test_set)

    test_precision <- precision(data=y_pred_test, reference=test_set$target, relevant=">50K")
    test_recall <- recall(data=y_pred_test, reference=test_set$target, relevant=">50K")
    test_f1 <- F_meas(data=y_pred_test, reference=test_set$target, relevant=">50K")

    # Imprimir métricas
    print(paste("Train Precision: ", train_precision, " Recall: ", train_recall, " F1-Score ", train_f1))
    print(paste("Test Precision: ", test_precision, " Recall: ", test_recall, " F1-Score ", test_f1))

    # Devolver modelo y  f1 score
    return(list(test_f1, model_nb))
}
```

Definimos los valores de los hiperparámetros que se usarán en Grid Search. La función de Naive Bayes no admite grid search, por lo que se ha implementado a mano utilizando bucles for anidados. Los hiperparámetros usados
son laplace y epsilon, que permiten configurar el suavizado de la probabilidad, evitando que la probabilidad de pertenencia a una clase sea 0. Ejecutamos la función definida en el chunk anterior con todas las configuraciones definidas,
obteniendo el mejor modelo.

```{r}
# Se entrenarán un total de 16 modelos, seleccionando el mejor de todos
laplace_values <- c(0, 0.5, 1, 10)
eps_values <- c(0.01, 0.1, 0.3, 1.0)

# Contador de configuraciones
i<-1

# Orden: Laplace, epsilon
best_configuration <- c(1000, 1000)
best_f1_score <- 0.0
best_model <- NULL


for(laplace_value in laplace_values) {
    for(eps_value in eps_values) {


        # Entrenamos el modelo con la configuración actual
        training_result <- train_and_evaluate_naive_bayes_with_configuration(i, train, test, laplace_value, eps_value)
        i <- i + 1

        # Commparamos con el mejor modelo actual
        if(training_result[[1]] > best_f1_score) {
            best_f1_score = training_result[[1]]
            best_model = training_result[[2]]
            best_configuration = c(laplace_value, eps_value)
        }

        
    }
}



```

# Interpretación de los resultados.
Podemos ver que la configuración de los hiperparámetros no ha tenido demasiado impacto en los resultados obtenidos, ya que todos los modelos han obtenido un F1-Score en el conjunto de pruebas que oscilaba entre un 0.6568 y un 0.6573, siendo los mejores modelos (aunque por una diferencia ínfima) aquellos 
con un valor de laplace igual a 0. Las métricas y la matriz de confusión revelan que existe una cantidad considerable de falsos positivos en la clasificación (esto se ve reflejado, por ejemplo, en los bajos valores de precision), lo que muestra que el modelo tiene cierta tendencia a clasificar instancias negativas (<=50K)
como positivas (>50K).

```{r}
# Imprimimos la configuración que obtuvo el mejor modelo
print("/////////////////////////////////////////")
print("Mejor configuración:")
print(paste("Laplace: ", best_configuration[1], ", eps: ", best_configuration[2]))
print("Métricas: ")

y_pred_train <- predict(best_model, newdata = train)
cm_train <- confusionMatrix(data=y_pred_train, reference=train$target, positive=">50K", mode = "prec_recall")
train_precision <- precision(data=y_pred_train, reference=train$target, relevant=">50K")
train_recall <- recall(data=y_pred_train, reference=train$target, relevant=">50K")
train_f1 <- F_meas(data=y_pred_train, reference=train$target, relevant=">50K")

y_pred_test <- predict(best_model, newdata = test)
cm_test <- confusionMatrix(data=y_pred_test, reference=test$target, positive=">50K", mode = "prec_recall")
test_precision <- precision(data=y_pred_test, reference=test$target, relevant=">50K")
test_recall <- recall(data=y_pred_test, reference=test$target, relevant=">50K")
test_f1 <- F_meas(data=y_pred_test, reference=test$target, relevant=">50K")

print(paste("Precision train: ", train_precision, "Precision test: ", test_precision))
print(paste("Recall train: ", train_recall, "Recall test: ", test_recall))
print(paste("F1-Score train: ", train_f1, " F1-Score test: ", test_f1))

```

Matrices de confusión:
```{r}
cm_train
cm_test	
```

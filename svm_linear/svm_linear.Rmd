---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
set.seed(123) # se establece la semilla para que cada vez que se ejecute el notebook desde el principio salga lo mismo

require(caret)
library(doParallel)
```

```{r}

train_data <- read.csv("../dataset/train_preprocessed.data", sep=",")
test_data <- read.csv("../dataset/test_preprocessed.data", sep=",")

```

```{r}
y_train <- factor(train_data$target, levels=rev(levels(factor(train_data$target))))
x_train <- train_data[0:13]
y_test <- factor(test_data$target, levels=rev(levels(factor(test_data$target))))
x_test <- test_data[0:13]

x_train$workclass <- factor(x_train$workclass)
x_train$education <- factor(x_train$education)
x_train$marital_status <- factor(x_train$marital_status)
x_train$occupation <- factor(x_train$occupation)
x_train$relationship <- factor(x_train$relationship)
x_train$race <- factor(x_train$race)
x_train$sex <- factor(x_train$sex)

x_test$workclass <- factor(x_test$workclass)
x_test$education <- factor(x_test$education)
x_test$marital_status <- factor(x_test$marital_status)
x_test$occupation <- factor(x_test$occupation)
x_test$relationship <- factor(x_test$relationship)
x_test$race <- factor(x_test$race)
x_test$sex <- factor(x_test$sex)

# min-max normalization
normalize <- function(x_train, x_test) {
  return ((x_train - min(x_train, x_test)) / (max(x_train, x_test) - min(x_train, x_test)))
}

x_train$age <- normalize(x_train$age, x_test$age)
x_train$fnlwgt <- normalize(x_train$fnlwgt, x_test$fnlwgt)
x_train$capital_gain <- normalize(x_train$capital_gain, x_test$capital_gain)
x_train$capital_loss <- normalize(x_train$capital_loss, x_test$capital_loss)
x_train$hours_per_week <- normalize(x_train$hours_per_week, x_test$hours_per_week)

x_test$age <- normalize(x_test$age, x_train$age)
x_test$fnlwgt <- normalize(x_test$fnlwgt, x_train$fnlwgt)
x_test$capital_gain <- normalize(x_test$capital_gain, x_train$capital_gain)
x_test$capital_loss <- normalize(x_test$capital_loss, x_train$capital_loss)
x_test$hours_per_week <- normalize(x_test$hours_per_week, x_train$hours_per_week)

# one-hot
dmy <- dummyVars(" ~ .", data=x_train)
x_train <- data.frame(predict(dmy, newdata = x_train))

dmy <- dummyVars(" ~ .", data=x_test)
x_test <- data.frame(predict(dmy, newdata = x_test))

x_test
```

```{r}
# empleo 4 cores de mi procesador
cl <- makePSOCKcluster(4)
registerDoParallel(cl)

# se crean todos los modelos con los parámetros de mlp_grid (tuning) y se evalúa su rendimiento
model <- train(x_train, 
               y_train, 
               metric = "F",
               method = "svmLinear",  
               trControl = trainControl(method = "repeatedcv", repeats = 10, 
                                        summaryFunction = prSummary, # calcula precision, recall y F1
                                        verboseIter = TRUE, 
                                        returnData = FALSE, 
                                        number = 10, 
                                        sampling = "down")) # number es el núm de veces que vuelve a entrenar

# dejo de emplear los 4 cores cuando he acabado de entrenar
stopCluster(cl)

#imprimo el modelo
model
```

```{r}
confusionMatrix(predict(model, newdata = x_test), y_test, mode = "prec_recall")
```
